{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    "    StochasticWeightAveraging\n",
    ")\n",
    "\n",
    "\n",
    "import models\n",
    "from dataset.dataset import TropicalCycloneDataset\n",
    "from dataset.transform import *\n",
    "from configs.configs_parser import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config \n",
    "def read_data_list(data_path, file_name):\n",
    "    with open(f\"{data_path}/{file_name}\", \"r\", encoding=\"utf-8\") as f: \n",
    "        data_list = f.read().splitlines()\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "data_config = load_config(\"./configs/dataset_configs.yml\")\n",
    "config = load_config(\"./configs/training_cfg.yml\")\n",
    "\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load model\n",
    "def load_model(checkpoint_path): \n",
    "\n",
    "    model = models.FullModel(arch=\"arch1\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "    \n",
    "    \n",
    "    df_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in checkpoint['state_dict'].items():\n",
    "        if k[6:] == 'n.pos_weight': \n",
    "            continue\n",
    "        else: \n",
    "            name = k[6:] \n",
    "            df_state_dict[name]=v\n",
    "\n",
    "    model.load_state_dict(df_state_dict)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "rootRawData = data_config['data']['rootRawData']\n",
    "rootSplitData = data_config['data']['rootSplitData']\n",
    "maxForecastTime = data_config['data']['maxForecastTime']\n",
    "\n",
    "trainSet = read_data_list(rootSplitData, \"train.txt\")\n",
    "valSet = read_data_list(rootSplitData, \"val.txt\")\n",
    "testSet = read_data_list(rootSplitData, \"test.txt\")\n",
    "\n",
    "\n",
    "\n",
    "varMean, varStd, varIsoChannels = getVarMeanAndStd()\n",
    "norm_Transformers = getNormTrans(varMean, varStd, varIsoChannels)\n",
    "trainAugmenters = getTrainAugmenter(norm_Transformers)\n",
    "evalAugmenters = getTestAugmenter(norm_Transformers)\n",
    "\n",
    "fillMode = \"zero\"\n",
    "\n",
    "test = TropicalCycloneDataset(testSet, rootRawData, transforms = evalAugmenters, maxForecastTime = maxForecastTime, fillMode = fillMode)\n",
    "\n",
    "\n",
    "# Data loader\n",
    "\n",
    "batch_size = config['training']['batch_size']\n",
    "num_workers = config['training']['num_workers']\n",
    "pwt = True\n",
    "\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False,  num_workers= num_workers,  persistent_workers= pwt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints \n",
    "root = \"./results/test_result\"\n",
    "exp = \"te\" #te, te_fill \n",
    "exp_h = \"36h.ckpt\"\n",
    "\n",
    "ckpt_path = f\"{root}/{exp}/{exp_h}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model wrapper\n",
    "# model = models.FullModel(arch=config['training']['model_arch'])\n",
    "# wrapper = models.ModelWrapper(model=model, learning_rate=config['training']['learning_rate'], decision_boundary=config['training']['decision_boundary'], pos_weight=config['training']['pos_weight'])\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # Define trainer\n",
    "\n",
    "# trainer = L.Trainer()\n",
    "\n",
    "# Get test result\n",
    "\n",
    "# trainer.test(model=wrapper, \n",
    "#             dataloaders=test_loader, \n",
    "#             ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC \n",
    "raw_model = load_model(checkpoint_path=ckpt_path)\n",
    "\n",
    "preds = [] \n",
    "targets = []\n",
    "for batch in test_loader: \n",
    "    X, labels = batch\n",
    "    predictions = nn.Sigmoid()(raw_model(X).squeeze(1))\n",
    "\n",
    "    targets.extend(labels.tolist())\n",
    "    preds.extend(predictions.tolist())\n",
    "\n",
    "preds = torch.tensor(preds)\n",
    "targets = torch.tensor(targets)\n",
    "\n",
    "auc = BinaryAUROC()\n",
    "auc.update(preds, targets)\n",
    "auc.compute()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
